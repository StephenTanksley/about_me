{
    "last_updated": "20250531",
    "first_name": "Stephen", 
    "last_name": "Tanksley",
    "phone_number": "214-952-0979",
    "email": "stephen.tanksley@gmail.com",
    "linkedin": "https://www.linkedin.com/in/stephentanksley",
    "github": "https://www.github.com/stephentanksley",
    "education": [
        {
            "institution": "Lambda School/Bloom School of Technology",
            "date_ended": "2020-10",
            "degree": "Non-degree certificate",
            "program": "Web Development/Computer Science"
        },
        {
            "institution": "Columbia College Chicago",
            "date_ended": "2015-06",
            "degree": "MFA",
            "program": "Master of Fine Arts - Music Composition for the Screen"
        },
        {
            "institution": "University of Minnesota - Duluth",
            "date_ended": "2012-06",
            "degree": "MM",
            "program": "Master of Music - Performance"
        },
        {
            "institution": "Wheaton College Conservatory of Music",
            "date_ended": "2010-06",
            "degree": "BM",
            "program": "Bachelor of Music - Performance"
        },
        {
            "institution": "Dallas Colleges",
            "date_ended": "2006-06",
            "degree": "No degree awarded",
            "program": "General studies/Music"
        }
    ],
"languages": ["Python", "SQL", "JavaScript", "Rust", "HTML", "CSS"],
    "frameworks_and_libraries": ["FastAPI", "PySpark", "Playwright", "Pytest", "SQLAlchemy", "ReactJS", "NodeJS", "Express"],
    "databases": ["PostgreSQL", "MS-SQL Server"],
    "architecture": ["Amazon Web Services (AWS)", "Docker", "Job Scheduler 7 (JS7)", "Pentaho Kettle"],
    "currently_learning": ["Rust", "AWS Glue", "AWS RDS", "AWS EC2", "Streamlit", "Apache Kafka"],
    "professional_experience": {
        "select_rehabilitation": {
            "title": "Application Engineer",
            "date_started": "2022-07",
            "date_ended": "present",
            "responsibilities": [
                "Architected extensible Docker-based Python CLI ETL utility to migrate data from MS-SQL Server to Postgres with optional intermediate transformations using Pandas and SQLAlchemy",
                "Created pre-commit hooks for Pentaho Kettle transformation files to standardize deployment across projects and eliminate regressions. Pre-commit hooks remove connection details baked into the file (username, password, hostname, database, port, etc) and enable all steps to render the transformation active, removing the need for redeploys of code due to disabled hops",
                "Separated master config into discrete JSON config files per table to allow utility to run with arbitrary tables, reducing debugging time and improving developer experience. Prior iteration of configs had all jobs running in a single large batch, requiring a restart from the beginning if any steps failed",
                "Converted scheduled workflows to event-driven workflows using Job Scheduler 7 for orchestration",
                "Provided Python language experience and instruction to colleagues less familiar with the language",
                "Implemented setup script to automate Python environment setup for new projects, reducing time needed to spin up a new project by approximately 50% and ensuring consistency across codebases",
                "Integrated new facility data container into daily ETL workflow by developing and testing all processes in parallel with current production environment",
                "Modeled and tested new views designed to remove unreliable worker information from Payroll Based Journaling stored procedures. Updated views reduced the number of workers with data discrepancies from ~125 to <5 per reporting period, easing burdens on HIPAA compliance efforts",
                "Deployed an integration test suite using PyTest for testing PostgreSQL to PostgreSQL transfers (full, recent records only, and date range), contributing to data quality check automation"
            ]
        },
        "jll_technologies": {
            "title": "Data Engineer I",
            "date_started": "2021-07",
            "date_ended": "2022-07",
            "responsibilities": [
                "Contributed to ongoing redesign and improvement of PySpark ETL framework using Azure services",
                "Scheduled ETL jobs to write to SQL marts/Delta Lake",
                "Contributed to unit/integration test suites to ensure confidence in new features and reduce regressions",
                "Spearheaded ingestion project to migrate orphaned data from local data warehouse to central data lake. This project was responsible for migrating approximately 400,000 missing records and exposed a bug which interfered with a clustering algorithm",
                "Standardized setup and deployment documentation to enhance team efficiency. Reduced setup time for new developers from 6 to 2 hours by removing redundant and misleading directions from stale documentation",
                "Collaborated with other teams to migrate from one-off ETL scripts to a config-driven framework",
                "Published a tagged directory of internal subject matter experts to aid ingestion work by removing ambiguity about who to ask when questions arise"
            ]
        }
    },
    "personal_projects": {
        "pathfinder_docker_server": {
            "description": "Developed a solution to host an instance of Foundry Virtual Tabletop (VTT) software in Docker container hosted locally on a Raspberry Pi 4 using secure tunnel through Cloudflare",
            "responsibilities": [
                "Migrated an existing Foundry installation from a Windows PC to a Raspberry Pi 4",
                "Developed a Docker Compose configuration to publish the VTT instance to a Docker container",
                "Configured a Cloudflare secure tunnel to permit remote connections to the game server"
            ],
            "deployed_url": "https://host.endtimes-foundry.online"
        },
        "bike_share_data_pipeline": {
            "description": "Originally intended only to be a project to practice data engineering from scratch without following a tutorial, this project is a data pipeline to retrieve, process and publish data from Chicago's Divvy Bike Share open data repository into an interactive application to promote bicycle usage",
            "responsibilities": [
                "Architected PostgreSQL database from scratch using 'rides' as a fact table and enriching it with dimension tables describing 'stations', 'station_distances'",
                "Developed Playwright web crawler to scrape CSV files from Divvy's AWS S3 bucket and download them to a local directory",
                "Implemented ingestion/transformation workflow to enrich and load data to PostgreSQL development database hosted in Docker",
                "Wrote an async rate-limited request utility to make 380k+ requests to Mapbox's Directions API to enrich Divvy station data with turn by turn directions and distance measurements",
                "Wrote data application with Streamlit to allow users to explore relevant data by including fine-grained controls for date and time selection",
                "Wrote copy for the application illustrating environmental impacts of current levels of bike share adoption on carbon emissions, physical space saved by taking a bike vs. motor vehicle"
            ],
            "to_do": [
                "Write module to demonstrate average financial savings of adopting mass transit and bicycles vs. motor vehicles",
                "Write module to demonstrate average health outcomes of bicycle adoption vs motor vehicles", 
                "Write module to allow users of the app to contact their own local elected representatives to advocate for safer, more sustainable transit investments via newsletter and letter writing campaigns",
                "Write module demonstration source citation for all academic references used to create the app"
            ],
            "article_urls": [
                "https://www.linkedin.com/pulse/practicing-data-engineering-from-scratch-how-upended-tanksley-yrzgc", 
                "https://www.linkedin.com/pulse/practicing-data-engineering-from-scratch-how-upended-tanksley-u3thc"
                ]
        }
    }
}